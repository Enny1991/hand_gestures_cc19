{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import sys\n",
    "import copy\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from scipy.signal import stft\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from tqdm import tqdm\n",
    "from utils import Person, simple_low_pass, exp_feat, window_spikes, analyze, do_tc_full\n",
    "import pickle as pkl\n",
    "import peakutils\n",
    "import pywt\n",
    "\n",
    "from jAER_utils.converter import aedat2numpy\n",
    "from utils import analyze\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from sklearn.feature_extraction.image import extract_patches_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general stuff\n",
    "fs = 200  # sampling frequency of MYO\n",
    "VERBOSE = True\n",
    "data_dir = '/Users/enea/Dropbox/Capocaccia2019_Gesture_DVS_Myo/Dataset/'\n",
    "classes = classes = ['pinky', 'elle', 'yo', 'index', 'thumb']\n",
    "classes_dict = {'pinky': 0, 'elle': 1, 'yo': 2, 'index': 3, 'thumb': 4}\n",
    "classes_inv = {v: k for k, v in classes_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all data into subject obects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = {}\n",
    "names = [name for name in listdir(data_dir) if \"emg\" in name]\n",
    "for name in names:\n",
    "    _emg = np.load(data_dir + '{}'.format(name)).astype('float32')\n",
    "    _ann = np.concatenate([np.array(['none']), np.load(data_dir + '{}'.format(name.replace(\"emg\",\"ann\")))[:-1]])\n",
    "    \n",
    "    subjects[name.split(\"_\")[1]] = Person(name.split(\"_\")[1], _emg, _ann, classes=classes)\n",
    "    \n",
    "    if VERBOSE:\n",
    "        print(\"Loaded {}: EMG = [{}] // ANN = [{}]\".format(name.split(\"_\")[1], _emg.shape, len(_ann)))\n",
    "print(\"Data Loaded! {} Sessions\".format(len(subjects.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separates data in correct trial type\n",
    "for name, data in subjects.items():\n",
    "    for _class in classes:\n",
    "        _annotation = np.float32(data.ann == _class)\n",
    "        derivative = np.diff(_annotation)/1.0\n",
    "        begins = np.where(derivative == 1)[0]\n",
    "        ends = np.where(derivative == -1)[0]\n",
    "        for b, e in zip(begins, ends):\n",
    "            _trials = data.emg[b:e]\n",
    "            data.trials[_class].append(_trials)\n",
    "            data.begs[_class].append(b)\n",
    "            data.ends[_class].append(e)\n",
    "print(\"Done sorting trials!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now every subject has different fields, each field is a dictionary and the keys are the gestures.\n",
    "We have the following fields: begs (beginning time of trials), ends (end time of trials), trials (actual myo data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example, see that each gesture is 2 seconds\n",
    "print(np.array(subjects['Gemma1'].begs['elle']) / fs)\n",
    "print(np.array(subjects['Gemma1'].ends['elle']) / fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to find the zero timestepping of the davis\n",
    "def find_trigger(ts):\n",
    "    return np.where(np.diff(ts) < 0)[0][0]\n",
    "\n",
    "def create_frame(x, y, dim=(128, 128)):\n",
    "    img = np.zeros(dim)\n",
    "    for _x, _y in zip(x.astype('int32'), y.astype('int32')):\n",
    "        img[dim[0] - 1 - _x,_y] += 1\n",
    "    return np.log10(img / np.max(img) + 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'Bruno2'\n",
    "# decoders takes some time since it is a very long recordings, especially with DAVIS\n",
    "events = aedat2numpy(data_dir + subject +'_dvs.aedat')\n",
    "events = events[:, find_trigger(events[2]):]\n",
    "events[2] = events[2] / 1e3\n",
    "print(events.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture = 'thumb'\n",
    "trial = 3\n",
    "# load beginning and end \n",
    "b = np.array(subjects[subject].begs[gesture][trial]) / fs\n",
    "e = np.array(subjects[subject].ends[gesture][trial]) / fs\n",
    "\n",
    "frame_size = 1.\n",
    "shift = 1.\n",
    "beginning = b + shift\n",
    "ending = beginning + frame_size\n",
    "# slice\n",
    "sl = (events[2] > beginning) & (events[2] < ending)\n",
    "\n",
    "img = events[:, sl]\n",
    "print(img.shape)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20,10))\n",
    "\n",
    "beg_int = int(shift * fs)\n",
    "end_int = int((shift + frame_size) * fs)\n",
    "\n",
    "# dd = subjects[subject].trials[gesture][trial][beg_int:end_int]\n",
    "# feat = analyze(dd, frame_len=0.01, frame_step=0.005, feat='RMS')\n",
    "# for i in range(8):\n",
    "#     _ = ax[1].plot(dd[:, i], label='channel{}'.format(i))\n",
    "# ax[1].legend()\n",
    "\n",
    "sll = (img[1] > 20) & (img[1] < 110) & (img[0] > 20) & (img[0] < 110)\n",
    "\n",
    "frame = np.uint8(create_frame(img[1][sll], img[0][sll]) * 254)\n",
    "blurred = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "thresh = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "M = cv2.moments(thresh)\n",
    "x = int(M[\"m10\"] / M[\"m00\"])\n",
    "y = int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "_ = ax[0].imshow(frame)\n",
    "ax[0].plot([x - 30, x + 30, x + 30, x - 30, x - 30], \n",
    "           [y  - 30, y  - 30, y + 30, y  + 30, y  - 30], '--', linewidth=7)\n",
    "\n",
    "_ = ax[1].imshow(frame[y - 30: y + 30, x-30:x+30])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (img[0] > (x - 30)) & (img[0] < (x + 30))\n",
    "b = (img[1] > (127 - y - 30)) & (img[1] < (127 - y + 30))\n",
    "xx = img[0][a & b]\n",
    "yy = img[1][a & b]\n",
    "ts = img[2][a & b]\n",
    "pol = img[3][a & b]\n",
    "\n",
    "plt.plot(xx, yy, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for subject, data in subjects.items():\n",
    "\n",
    "    # decoders takes some time since it is a very long recordings, especially with DAVIS\n",
    "    events = aedat2numpy(data_dir + subject +'_dvs.aedat')\n",
    "    events = events[:, find_trigger(events[2]):]\n",
    "    events[2] = events[2] / 1e3\n",
    "    \n",
    "    for gesture in classes:\n",
    "        for trial in range(5):\n",
    "            print(\"{} :: {} :: {}\".format(subject, gesture, trial))\n",
    "            # load beginning and end \n",
    "            b = np.array(data.begs[gesture][trial]) / fs\n",
    "            e = np.array(data.ends[gesture][trial]) / fs\n",
    "\n",
    "            frame_size = 2\n",
    "            shift = 0.\n",
    "            beginning = b + shift\n",
    "            ending = beginning + frame_size\n",
    "\n",
    "            # slice\n",
    "            sl = (events[2] > beginning) & (events[2] < ending)\n",
    "\n",
    "            img = events[:, sl]\n",
    "\n",
    "            beg_int = int(shift * fs)\n",
    "            end_int = int((shift + frame_size) * fs)\n",
    "\n",
    "            sll = (img[1] > 20) & (img[1] < 110) & (img[0] > 20) & (img[0] < 110)\n",
    "\n",
    "            frame = np.uint8(create_frame(img[1][sll], img[0][sll]) * 254)\n",
    "            blurred = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "            thresh = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "            M = cv2.moments(thresh)\n",
    "            x = int(M[\"m10\"] / M[\"m00\"])\n",
    "            y = int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "            a = (img[0] > (x - 30)) & (img[0] < (x + 30))\n",
    "            b = (img[1] > (127 - y - 30)) & (img[1] < (127 - y + 30))\n",
    "            xx = img[0][a & b]\n",
    "            yy = img[1][a & b]\n",
    "            ts = img[2][a & b]\n",
    "            pol = img[3][a & b]\n",
    "\n",
    "            data.x[gesture].append(xx - min(xx))\n",
    "            data.y[gesture].append(yy - min(yy))\n",
    "            data.ts[gesture].append(ts - min(ts))\n",
    "            data.pol[gesture].append(pol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(subjects, open('10_people_dvs_emg.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pkl.load(open('10_people_dvs_emg.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = 'Melika2'\n",
    "trial = 1\n",
    "gesture = 'index'\n",
    "_x = data[sub].y[gesture][trial]\n",
    "_y = data[sub].x[gesture][trial]\n",
    "_ts = data[sub].ts[gesture][trial]\n",
    "_p = data[sub].pol[gesture][trial]\n",
    "\n",
    "fil = (_ts > 0.25) & (_ts < 1)\n",
    "frame = create_frame(_x[fil], _y[fil], dim=(60, 60))\n",
    "plt.imshow(frame)\n",
    "plt.figure()\n",
    "_ = plt.plot(data[sub].trials[gesture][trial])\n",
    "\n",
    "\n",
    "frame = np.uint8(frame * 254)\n",
    "blurred = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "thresh = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "(kps, descs) = sift.detectAndCompute(thresh, None)\n",
    "\n",
    "print(\"# kps: {}, descriptors: {}\".format(len(kps), descs.shape))\n",
    "\n",
    "surf = cv2.xfeatures2d.SURF_create()\n",
    "(kps, descs) = surf.detectAndCompute(thresh, None)\n",
    "print(\"# kps: {}, descriptors: {}\".format(len(kps), descs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract sift and surf \n",
    "for subject, sub in data.items():\n",
    "    for gesture in classes:\n",
    "        for trial in range(5):\n",
    "\n",
    "            _x = sub.y[gesture][trial]\n",
    "            _y = sub.x[gesture][trial]\n",
    "            _ts = sub.ts[gesture][trial]\n",
    "            _p = sub.pol[gesture][trial]\n",
    "\n",
    "            fil = (_ts > 0.200) & (_ts < 2)\n",
    "            frame = create_frame(_x[fil], _y[fil], dim=(60, 60))\n",
    "\n",
    "            frame = np.uint8(frame * 254)\n",
    "            blurred = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "            thresh = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "            sift = cv2.xfeatures2d.SIFT_create()\n",
    "            (kps, descs1) = sift.detectAndCompute(thresh, None)\n",
    "            sub.sift[gesture].append(descs1)\n",
    "\n",
    "            surf = cv2.xfeatures2d.SURF_create()\n",
    "            (kps, descs2) = surf.detectAndCompute(thresh, None)\n",
    "            sub.surf[gesture].append(descs2)\n",
    "            \n",
    "            print(\"{}::{}::{}::{}::{}\".format(subject, gesture, trial, descs1.shape, descs2.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = []\n",
    "X2 = []\n",
    "Y = []\n",
    "\n",
    "for subject, sub in data.items():\n",
    "    for gesture in classes:\n",
    "        for trial in range(5):\n",
    "            if sub.sift[gesture][trial].shape[0] >= 7 and sub.surf[gesture][trial].shape[0] >= 7: \n",
    "                X1.append(sub.sift[gesture][trial][:7])\n",
    "                X2.append(sub.surf[gesture][trial][:7])\n",
    "                Y.append(classes_dict[gesture])\n",
    "            \n",
    "\n",
    "X1 = np.array(X1)\n",
    "X2 = np.array(X2)\n",
    "X = np.hstack([X1.reshape(X1.shape[0], -1), X2.reshape(X1.shape[0], -1)])\n",
    "Y = np.array(Y)\n",
    "\n",
    "X -= np.mean(X, 0, keepdims=True)\n",
    "X /= np.std(X, 0, keepdims=True) + 1e-15\n",
    "\n",
    "print(np.array(X1).shape)\n",
    "print(np.array(X2).shape)\n",
    "print(np.array(Y).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(do_tc_full(X, Y.reshape(-1,1 ), pca_comp=4, avg=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract sift and surf \n",
    "\n",
    "X1 = []\n",
    "X2 = []\n",
    "Y = []\n",
    "\n",
    "for subject, sub in data.items():\n",
    "    if subject not in ['Enea3', 'Melika2']:\n",
    "        for gesture in classes:\n",
    "            for trial in range(5):\n",
    "\n",
    "                _emg = sub.trials[gesture][trial]\n",
    "\n",
    "                if _emg.shape[0] < 400:\n",
    "                    _emg = np.vstack([_emg, np.zeros((400 - _emg.shape[0], 8))])\n",
    "                _emg = _emg[80:400]\n",
    "                X2.append(_emg.reshape(-1, 40, 8))\n",
    "\n",
    "                _x = sub.y[gesture][trial]\n",
    "                _y = sub.x[gesture][trial]\n",
    "                _ts = sub.ts[gesture][trial]\n",
    "                _p = sub.pol[gesture][trial]\n",
    "                for i in [0.4, 0.6, 0.8, 1., 1.2, 1.4, 1.6, 1.8]:\n",
    "                    fil = (_ts > i) & (_ts < i + .2)\n",
    "                    frame = create_frame(_x[fil], _y[fil], dim=(60, 60))\n",
    "                    X1.append(frame)\n",
    "                    Y.append(classes_dict[gesture])\n",
    "#                     print(\"{}::{}::{}::{}::{}\".format(subject, gesture, trial, frame.shape, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.array(X1)\n",
    "X2 = np.array(X2).reshape(-1, 40, 8)\n",
    "Y = np.array(Y).reshape(-1, 1)\n",
    "\n",
    "print(np.array(X1).shape)\n",
    "print(np.array(X2).shape)\n",
    "print(np.array(Y).shape)\n",
    "\n",
    "# np.save('_cc19_hand_gestures_10p_img', X1)\n",
    "np.save('_cc19_hand_gestures_10p_emg', X2)\n",
    "np.save('_cc19_hand_gestures_10p_lbl', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((X1[0] - np.min(X1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(10, 10, figsize=(20, 20))\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        _idx = np.random.randint(5600)\n",
    "        a = X1[_idx]\n",
    "        a -= np.min(a)\n",
    "        a /= np.max(a)\n",
    "        frame = np.uint8(a * 255)\n",
    "        blurred = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "        thresh = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY)[1]\n",
    "        ax[i][j].imshow(frame)\n",
    "        ax[i][j].set_title(classes_inv[Y[_idx][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_grid(img, size=(20, 20), shift=None):\n",
    "    if shift == None:\n",
    "        shift = size\n",
    "    x, y = img.shape\n",
    "    patches = []\n",
    "    n_win_x = (x - size[0]) // shift[0] + 1\n",
    "    n_win_y = (y - size[1]) // shift[1] + 1\n",
    "    for i in range(n_win_x):\n",
    "        for j in range(n_win_y):\n",
    "            patches.append(img[i * shift[0]:i * shift[0] + size[0], j * shift[1]:j * shift[1] + size[1]])\n",
    "            \n",
    "    return patches\n",
    "\n",
    "pp = extract_grid(X1[100], (16, 16), shift=(8, 8))\n",
    "print(len(pp))\n",
    "fig, ax = plt.subplots(6, 6)\n",
    "for i, ppp in enumerate(pp):\n",
    "    ax[i//6][i % 6].imshow(ppp, aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SIFT features codebook\n",
    "all_V_sift = []\n",
    "all_patches = []\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "for j, img in enumerate(X1):\n",
    "    a = img\n",
    "    a -= np.min(a)\n",
    "    a /= np.max(a)\n",
    "    frame = np.uint8(a * 255)\n",
    "    \n",
    "    patches = extract_patches_2d(frame, (20, 20), max_patches=0.1)\n",
    "\n",
    "    print(\"{}::{}/{}\".format(len(patches), j, len(X1)))\n",
    "    _patches = []\n",
    "    for p in patches:\n",
    "        \n",
    "        (kps, descs1) = sift.detectAndCompute(p, None)\n",
    "        if descs1 is not None:\n",
    "            _patches.append(descs1)\n",
    "    all_V_sift.append(_patches)\n",
    "    \n",
    "for_kmeans = np.vstack([np.vstack(i) for i in all_V_sift])\n",
    "print(for_kmeans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(all_V_sift[0][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_kmeans = np.vstack([np.vstack(i) for i in all_V_sift])\n",
    "print(for_kmeans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('kepoints_20x20_168_sift', for_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_kmeans = np.load('kepoints_20x20_168_sift.npy')\n",
    "print(for_kmeans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans\n",
    "from sklearn.cluster import KMeans\n",
    "k = 500\n",
    "kmeans = KMeans(n_clusters=k, random_state=0).fit(for_kmeans[::5])\n",
    "C_sift = kmeans.cluster_centers_\n",
    "print(C_sift.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('centers_20x20_840_sift', C_sift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create histogram features\n",
    "all_h_sift = []\n",
    "\n",
    "for feat in enumerate(all_V_sift):\n",
    "    \n",
    "    h = np.zeros((k,))\n",
    "    \n",
    "    for p in feat:\n",
    "        _id = np.argmin(np.linalg.norm(p - C_sift, axis=1))\n",
    "        h[_id] += 1\n",
    "                \n",
    "    all_h_sift.append(h)\n",
    "\n",
    "    \n",
    "all_h_sift = np.array(all_h_sift)\n",
    "print(all_h_sift.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create histogram features\n",
    "all_h_sift = []\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "for j, img in enumerate(X1):\n",
    "    a = img\n",
    "    a -= np.min(a)\n",
    "    a /= np.max(a)\n",
    "    frame = np.uint8(a * 255)\n",
    "\n",
    "    patches = extract_grid(frame)\n",
    "    h = np.zeros((k,))\n",
    "    \n",
    "    for p in patches:\n",
    "        (kps, descs1) = sift.detectAndCompute(p, None)\n",
    "        \n",
    "        if descs1 is not None:\n",
    "            for d in descs1:\n",
    "                _id = np.argmin(np.linalg.norm(d - C_sift, axis=1))\n",
    "                h[_id] += 1\n",
    "                \n",
    "    all_h_sift.append(h)\n",
    "\n",
    "    \n",
    "all_h_sift = np.array(all_h_sift)\n",
    "print(all_h_sift.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_h_sift[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_XX = np.array([i / np.linalg.norm(i) for i in all_h_sift])\n",
    "\n",
    "print(do_tc_full(_XX, Y, avg=True, verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = X1[2113]\n",
    "im -= np.min(im)\n",
    "im /= np.max(im)\n",
    "print(im.mean())\n",
    "fig, ax = plt.subplots(2, 3)\n",
    "ax[0][0].imshow(im)\n",
    "\n",
    "im = np.float32(im)\n",
    " \n",
    "# Calculate gradient \n",
    "gx = cv2.Sobel(im, cv2.CV_32F, 1, 0, ksize=1)\n",
    "gy = cv2.Sobel(im, cv2.CV_32F, 0, 1, ksize=1)\n",
    "print(gy.shape)\n",
    "ax[0][1].imshow(np.abs(gx))\n",
    "ax[0][2].imshow(np.abs(gy))\n",
    "\n",
    "# mag angle\n",
    "mag, angle = cv2.cartToPolar(gx, gy, angleInDegrees=True)\n",
    "ax[1][0].imshow(np.abs(mag))\n",
    "ax[1][1].imshow(angle)\n",
    "plt.tight_layout()\n",
    "\n",
    "patches = extract_grid(im, (8, 8))\n",
    "kk = patches[17]\n",
    "gx_p = cv2.Sobel(kk, cv2.CV_32F, 1, 0, ksize=1)\n",
    "gy_p = cv2.Sobel(kk, cv2.CV_32F, 0, 1, ksize=1)\n",
    "\n",
    "# mag angle\n",
    "mag_p, angle_p = cv2.cartToPolar(gx_p, gy_p, angleInDegrees=True)\n",
    "angle_p = np.abs(angle_p - 180)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_BUCKETS = 9\n",
    "CELL_SIZE = 8  # Each cell is 8x8 pixels\n",
    "BLOCK_SIZE = 2  # Each block is 2x2 cells\n",
    "\n",
    "def assign_bucket_vals(m, d, bucket_vals):\n",
    "    left_bin = int(d / 20.) % N_BUCKETS\n",
    "    # Handle the case when the direction is between [160, 180)\n",
    "    if (d == 180.):\n",
    "        right_bin = 0\n",
    "    else:\n",
    "        right_bin = (int(d / 20.) + 1) % N_BUCKETS\n",
    "    \n",
    "    if left_bin < right_bin:\n",
    "        left_val= m * (right_bin * 20 - d) / 20\n",
    "        right_val = m * (d - left_bin * 20) / 20\n",
    "    else:\n",
    "        left_val= m * (d - left_bin * 20) / 20\n",
    "        right_val = m * (right_bin * 20 - d) / 20 \n",
    "    if left_val < 0:\n",
    "        left_val = 0.\n",
    "    if right_val < 0:\n",
    "        right_val = 0.\n",
    "    bucket_vals[left_bin] += np.abs(left_val)\n",
    "    bucket_vals[right_bin] += np.abs(right_val)\n",
    "    \n",
    "all_veat = []\n",
    "for j, im in enumerate(X1):\n",
    "    im -= np.min(im)\n",
    "    im /= np.max(im)\n",
    "    im = np.float32(im)\n",
    "    blocks = extract_grid(im, (16, 16), (8, 8))\n",
    "\n",
    "    all_buckets = []\n",
    "    for block in blocks:\n",
    "        cells = extract_grid(block, (8, 8))\n",
    "        to_concat = []\n",
    "        for cell in cells:\n",
    "            bucket_vals = np.zeros((N_BUCKETS))\n",
    "            gx_p = cv2.Sobel(cell, cv2.CV_32F, 1, 0, ksize=1)\n",
    "            gy_p = cv2.Sobel(cell, cv2.CV_32F, 0, 1, ksize=1)\n",
    "\n",
    "            # mag angle\n",
    "            mag_p, angle_p = cv2.cartToPolar(gx_p, gy_p, angleInDegrees=True)\n",
    "            mag_p = np.abs(mag_p)\n",
    "            angle_p = np.abs(angle_p - 180)\n",
    "            for m, d in zip(mag_p.reshape(-1,), angle_p.reshape(-1)):\n",
    "                assign_bucket_vals(m, d, bucket_vals)\n",
    "            to_concat.append(bucket_vals)\n",
    "        veat = np.array(to_concat)\n",
    "        all_buckets.append(veat)\n",
    "\n",
    "    veat = np.array(all_buckets)\n",
    "    all_veat.append(veat)\n",
    "    print(j)\n",
    "\n",
    "print(np.array(all_veat).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-15\n",
    "print(np.array(all_veat).shape)\n",
    "all_veat_res = np.array(all_veat).reshape(5600, 36, -1)\n",
    "# eps = 1e-7\n",
    "all_veat_res /= np.sqrt(np.sum(all_veat_res ** 2, 2, keepdims=True) + eps + 1)\n",
    "# all_veat_res = np.sqrt(all_veat_res)\n",
    "# all_veat_res /= np.linalg.norm(all_veat_res, axis=2, keepdims=True) + eps\n",
    "# all_veat_norm = all_veat_res / (np.linalg.norm(all_veat_res, axis=1, keepdims=True) + 1e-15)\n",
    "# all_veat_norm = all_veat_res\n",
    "all_veat_final = all_veat_res.reshape(5600, -1)\n",
    "# all_veat_final = all_veat_final / (np.linalg.norm(all_veat_final, axis=1, keepdims=True) + 1e-15)\n",
    "\n",
    "print(all_veat_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(all_veat_res ** 2, 2, keepdims=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('hog_16x16_8x8_sqrt_norm', all_veat_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_tr, acc_te, _, _ = do_tc_full(all_veat_final, np.array(Y).reshape(-1,1), pca_comp=300, verbose=True, avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5600, 3, 8)\n"
     ]
    }
   ],
   "source": [
    "# emg = np.load('_cc19_hand_gestures_10p_emg.npy')\n",
    "# emg_mav = np.array([analyze(i, frame_len=0.2, frame_step=0.2, feat='MAV') for i in emg])\n",
    "# emg_sd = np.array([analyze(i, frame_len=0.2, frame_step=0.2, feat='SD') for i in emg])\n",
    "# emg_rms = np.array([analyze(i, frame_len=0.2, frame_step=0.2, feat='RMS') for i in emg])\n",
    "\n",
    "print(np.hstack([emg_mav, emg_rms, emg_sd]).shape)\n",
    "emg = np.hstack([emg_mav, emg_rms, emg_sd]).reshape(-1, 24)\n",
    "np.save('emg_mav_rms_sd_02', emg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5600, 24)\n",
      "(5600, 1296)\n",
      "(5600, 1)\n"
     ]
    }
   ],
   "source": [
    "dvs = np.load('hog_16x16_8x8_sqrt_norm.npy')\n",
    "emg = np.load('emg_mav_rms_sd_02.npy')\n",
    "lbl = np.load('_cc19_hand_gestures_10p_lbl.npy')\n",
    "print(emg.shape)\n",
    "print(dvs.shape)\n",
    "print(lbl.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7881 :: 0.7666\n"
     ]
    }
   ],
   "source": [
    "emg -= np.mean(emg, 0, keepdims=True)\n",
    "emg /= np.std(emg, 0, keepdims=True) + 1e-15\n",
    "acc_tr, acc_te, _, _ = do_tc_full(emg, lbl, pca_comp=0, verbose=False, avg=True, kernel='rbf')\n",
    "print(\"{:.4} :: {:.4}\".format(acc_tr, acc_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on: 5040 / Test on 560\n",
      "Fold 0: Train acc: 0.957 || Test acc: 0.839\n",
      "Fold 1: Train acc: 0.96 || Test acc: 0.82\n",
      "Fold 2: Train acc: 0.959 || Test acc: 0.848\n",
      "Fold 3: Train acc: 0.958 || Test acc: 0.834\n",
      "Fold 4: Train acc: 0.958 || Test acc: 0.848\n",
      "Fold 5: Train acc: 0.958 || Test acc: 0.839\n",
      "Fold 6: Train acc: 0.961 || Test acc: 0.839\n",
      "Fold 7: Train acc: 0.958 || Test acc: 0.843\n",
      "Fold 8: Train acc: 0.959 || Test acc: 0.827\n",
      "Fold 9: Train acc: 0.96 || Test acc: 0.852\n",
      "0.9588 :: 0.8389\n"
     ]
    }
   ],
   "source": [
    "dvs -= np.mean(dvs, 0, keepdims=True)\n",
    "dvs /= np.std(dvs, 0, keepdims=True) + 1e-15\n",
    "acc_tr, acc_te, _, _ = do_tc_full(dvs, lbl, pca_comp=0, verbose=True, avg=True, kernel='rbf')\n",
    "print(\"{:.4} :: {:.4}\".format(acc_tr, acc_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on: 5040 / Test on 560\n",
      "Fold 0: Train acc: 0.981 || Test acc: 0.889\n",
      "Fold 1: Train acc: 0.98 || Test acc: 0.896\n",
      "Fold 2: Train acc: 0.979 || Test acc: 0.907\n",
      "Fold 3: Train acc: 0.981 || Test acc: 0.909\n",
      "Fold 4: Train acc: 0.978 || Test acc: 0.889\n",
      "Fold 5: Train acc: 0.979 || Test acc: 0.884\n",
      "Fold 6: Train acc: 0.981 || Test acc: 0.875\n",
      "Fold 7: Train acc: 0.98 || Test acc: 0.855\n",
      "Fold 8: Train acc: 0.98 || Test acc: 0.857\n",
      "Fold 9: Train acc: 0.98 || Test acc: 0.868\n",
      "0.9798 :: 0.883\n"
     ]
    }
   ],
   "source": [
    "acc_tr, acc_te, _, _ = do_tc_full(np.hstack([emg, dvs]), lbl, pca_comp=0, verbose=True, avg=True, kernel='rbf')\n",
    "print(\"{:.4} :: {:.4}\".format(acc_tr, acc_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random location [200, 200] as an example.\n",
    "loc_x = loc_y = 200\n",
    "\n",
    "ydata = get_magnitude_hist_block(loc_x, loc_y)\n",
    "ydata = ydata / np.linalg.norm(ydata)\n",
    "\n",
    "xdata = range(len(ydata))\n",
    "bucket_names = np.tile(np.arange(N_BUCKETS), BLOCK_SIZE * BLOCK_SIZE)\n",
    "\n",
    "assert len(ydata) == N_BUCKETS * (BLOCK_SIZE * BLOCK_SIZE)\n",
    "assert len(bucket_names) == len(ydata)\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.bar(xdata, ydata, align='center', alpha=0.8, width=0.9)\n",
    "plt.xticks(xdata, bucket_names * 20, rotation=90)\n",
    "plt.xlabel('Direction buckets')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.grid(ls='--', color='k', alpha=0.1)\n",
    "plt.title(\"HOG of block at [%d, %d]\" % (loc_x, loc_y))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hog = []\n",
    "\n",
    "for img in X1:\n",
    "    # HOG\n",
    "    a = img\n",
    "    a -= np.min(a)\n",
    "    a /= np.max(a)\n",
    "    frame = np.uint8(a * 255)\n",
    "\n",
    "    patches = extract_grid(frame, (8, 8))\n",
    "\n",
    "    all_hist = []\n",
    "\n",
    "    for p in patches:\n",
    "        gx = cv2.Sobel(p, cv2.CV_32F, 1, 0)\n",
    "        gy = cv2.Sobel(p, cv2.CV_32F, 0, 1)\n",
    "\n",
    "\n",
    "        mag, ang = cv2.cartToPolar(gx, gy)\n",
    "        bin_n = 16\n",
    "        bin = np.int32(bin_n*ang/(2*np.pi))\n",
    "        bin_cells = bin[:100,:100], bin[100:,:100], bin[:100,100:], bin[100:,100:]\n",
    "        mag_cells = mag[:100,:100], mag[100:,:100], mag[:100,100:], mag[100:,100:]\n",
    "        hists = [np.bincount(b.ravel(), m.ravel(), bin_n) for b, m in zip(bin_cells, mag_cells)]\n",
    "        hist = np.hstack(hists)\n",
    "        all_hist.append(hist)\n",
    "    # transform to Hellinger kernel\n",
    "    hist = sum(all_hist)\n",
    "    eps = 1e-7\n",
    "    hist /= hist.sum() + eps\n",
    "    hist = np.sqrt(hist)\n",
    "    hist /= np.linalg.norm(hist) + eps\n",
    "\n",
    "    all_hog.append(hist)\n",
    "print(np.array(all_hog).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_tr, acc_te = do_tc_full(np.array(all_hog), np.array(Y).reshape(-1,1), verbose=True, avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X, all_Y = [], []\n",
    "n_ch = 8\n",
    "preprocess = True\n",
    "frame_len = 0.3\n",
    "overlap = 0.0\n",
    "frame_step = frame_len * (1. - overlap)\n",
    "features = ['MAV', 'RMS', 'SD']\n",
    "n_comp = 8\n",
    "for i, idx in enumerate(X2):\n",
    "    _sub = np.mean(np.abs(idx), 0)\n",
    "    all_X.append(_sub)\n",
    "    all_Y.append(Y[i])\n",
    "\n",
    "all_X = np.vstack(all_X)\n",
    "all_Y = np.vstack(all_Y)\n",
    "\n",
    "all_X -= np.mean(all_X, 0, keepdims=True)\n",
    "all_X /= np.std(all_X, 0, keepdims=True) + 1e-15\n",
    "\n",
    "acc_tr, acc_te = do_tc_full(all_X, all_Y, verbose=True, pca_comp=n_comp, avg=False)\n",
    "print(\"Train: {:.4} +/- {:.4}\".format(np.mean(acc_tr), np.std(acc_tr)))\n",
    "print(\"Test: {:.4} +/- {:.4}\".format(np.mean(acc_te), np.std(acc_te)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "(kps, descs) = sift.detectAndCompute(frame, None)\n",
    "\n",
    "print(descs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('gesture.csv', 'w') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',')\n",
    "    csv_writer.writerow(['x', 'y', 'type'])\n",
    "    for i in range(img.shape[1]):\n",
    "        csv_writer.writerow([img[0, i], img[1, i], img[3, i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('gesture.csv')\n",
    "\n",
    "g = sns.jointplot(\"x\", \"y\", data=data, size=20)\n",
    "plt.savefig('spatial_density_yo.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "import scipy.stats as stats\n",
    "gm = GaussianMixture(4) \n",
    "gm.fit(img[0].reshape(-1, 1) / 180)\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "plt.hist(img[0] / 180, 50, density=True)\n",
    "plt.plot(x.reshape(-1, 1), stats.norm.pdf(x, gm.means_[0], gm.covariances_[0]).T)\n",
    "plt.plot(x.reshape(-1, 1), stats.norm.pdf(x, gm.means_[1], gm.covariances_[1]).T)\n",
    "plt.plot(x.reshape(-1, 1), stats.norm.pdf(x, gm.means_[2], gm.covariances_[2]).T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
